# Software Architecture: Patterns for Developers

## The Context of Software Architecture Patterns

### What are software architecture patterns?
- [Instructor] It's important to have a shared understanding of the term software architecture patterns, so let's try to come up with a definition. A pattern in software is basically a solution to a common problem. Many developers have encountered similar problems and devised good solutions. If you're facing the same type of problem, you might be able to solve it by applying that solution. Essentially, the pattern defines components and the interactions between them. We can compare it to writing. If you want to bring across a message, you can just start writing away wildly, saying whatever comes to mind, but that wouldn't help in communicating your message effectively. You could do better by structuring your text with an introduction, a body, and a conclusion. Here's another example. A lot of fantasy books follow what's called a three-act structure. First, the characters are introduced, and there is a problem which forces them to go on an adventure. Then there's the actual adventure, where the characters work towards a goal, and finally, there's the big finale in which they are usually victorious. There are many other writing and storytelling patterns, but the point is that they give both the author and the reader a structure that they can follow easily. Similarly, there are many different types of software patterns. What most developers think about when they hear the term are things like the repository, the singleton, the builder, or the factory pattern. These are patterns that define how to write and interact with certain pieces of code, often organized in classes. The repository pattern, for example, shows us how we can abstract away implementation details on how to retrieve data from a database. In a piece of our application, we call a repository containing the logic to build and send a SQL query to the database. It also contains the necessary code to translate the database response to the format that the application code will understand. Here's another example. To parse a string into an integer in C#, you can use the following code: int x = in.Parse("3");. This will return an integer. But what happens if we use a string that doesn't represent a number? Like, if we try to parse the text, hello. This will throw an exception. If we're not sure about the input, we can use the TryParse method, like this, int z = 0; if (int.TryParse (input, out z)). This function will not throw an exception if it can't parse the input. This is called the TryParse pattern. It can be found in several places in .NET. If you're writing a piece of code that needs to parse some input, you can follow this convention by writing a Parse function that throws an exception and a TryParse that doesn't. This makes it recognizable to other developers that will be using your code. So you see how we can encounter patterns at different levels in software. Sometimes it's just a single function. Sometimes it's about a module or a collection of modules, and it can even be about how a collection of applications interacts. In this course, we'll be looking above the single module or class level and see how to give structure to a complete application.

### Why software architecture patterns?
- [Instructor] Why do software architecture patterns exist at all? Can't we just write code and see how it evolves? Isn't that what Agile is all about? Well, using known patterns has significant advantages. We can compare it to the blueprint of a house. You can build a house without it, and you might end up with something fairly okay. But if you want to build something larger and more complex, you'll want a solid plan. This way, what you're building will last longer. Software patterns mean you don't have to spend time inventing solutions when they're already available. Using known patterns will make your code recognizable to other developers who join the project later on. This makes it easier for them to get up to speed, which is beneficial to the entire organization. The patterns are featured in many pieces of literature and documentation. If you have any questions about them, it's easy to find information, help, and reference implementations. Knowing several software architecture patterns means you can apply them to your projects. It allows you to weigh the pros and cons of taking different approaches, and it can help identify improvements you can make to the current architecture of your projects. Finally, these patterns improve the quality and structure of your application, reducing the risk of bugs or unmaintainable software. All these points allow you to become a more productive member of your team, and they make a team as a whole more productive. There are some caveats, however. The problem you're facing may have multiple possible solutions, making it difficult to make a choice. And there's no guarantee that the pattern will be the solution you remain happy with as time goes by. It's just that, for similar problems, certain patterns have proven to be very helpful for thousands of teams and organizations. So, it will be a good starting point for you as well. If a chosen pattern proves to be a bad solution in your case, then you can take a different approach. But in order to make that decision, you need to know about the different patterns. Software architecture patterns will make your applications better, and you as a developer as well.

### The difference with design patterns
- [Instructor] This course covers software architecture patterns. We won't be covering design patterns, so it's useful to look at where we draw the line. Let's define what design patterns are first. Design patterns define a small number of components that can be used in an application. They don't describe how the application itself should be structured. Design patterns only tell us what a specific piece of code must do, and how other pieces of code should interact with it. For example, the factory pattern tells us that we can write a customer factory class with a create method. The factory then has all the complex logic of creating a customer. Any other piece of code that needs to create a customer can just call this customer factory. But this pattern doesn't say anything about how other pieces of the application should be structured. Software architecture patterns occur at a higher level, or looking at many components and their interactions that make up a significant part of the application or even define it. For example, will we structure our application in distinct layers, or should we split it up into multiple independent processes on physically separated servers? And if we do, should they communicate over a central messaging system or directly with each other? Software architecture patterns will give you a holistic view of how you can develop your applications.

### Categories of patterns
- [Instructor] To get a better overview of the different types of software architecture patterns, we'll put them in three distinct categories. These three categories are System Patterns, Application Patterns and User Interface Patterns. System Patterns are software architecture patterns that help us create a single application as it is viewed by the end-user. This end-user can be a human person, but also another application. The system can also consist of multiple running processes behind the scenes, but this is usually hidden from the end-User. We'll start with the monolith, end-tier, service-oriented, microservices and serverless. Then, we'll look at some consequences of the distributed system architectures. And finally, we'll cover the peer-to-peer architecture. Application Patterns are a category of patterns that define how a single executable should be built. So it's about the internal structure of a single executable. This executable can be the only component in the system, or it can be part of a larger system with many components. In this category, we'll look at the layered pattern, the onion architecture, the ports and adapters or hexagonal architecture. We'll then look at the differences between layered onion and ports and adapters because they will look similar. Next, we'll continue with the modular monolith, the microkernel, command query responsibility segregation or CQRS, event sourcing, and finally, the combination of CQRS and event sourcing. The last category of software architecture patterns is all about the user interface. This is where we come close to design patterns, but they're an important part of the application. And sometimes, the UI is the application. So that's why I want to go over them in this course as well. We'll be looking at forms and controls, model view controller, model view presenter, and model view view model. We'll finish with a look at the differences between these patterns. Now that we have everything neatly put into categories, we're ready to start learning the actual patterns.

Q: How do software architecture patterns differ from software design patterns?
A: Architecture patterns define an important application part; design patterns describe a small number of components inside an application.

Q: Why should you use software architecture patterns?
A: They make development more efficient.

Q: What is a software architecture pattern?
A: a high-level solution to a problem that is commonly encountered in architecture development

## System Patterns

### Monolith
- [Instructor] The monolith is a simple architectural pattern, which is why it's so popular and you encounter it often. The monolith is an application that consists of a single executable that contains all the logic to solve the problem at hand. When a new feature is requested, the code is added to the existing source. Even though the monolith has a bad reputation, it does have advantages when applied correctly. First, it's a simple architecture that is easy to understand, implement, and test. Because of its simplicity, it's usually easy to deploy. There isn't a big need for coordination with other systems or teams. This makes it ideal for projects with a limited scope or to get started. But once the application starts to grow, the disadvantages can become apparent. In a monolith, tight coupling is easily introduced by accident. This makes it harder to move all pieces of logic to other applications later. Even though the monolith doesn't mean complex code by definition, it has often led to situations where developers find it hard to modify or extend the application. Another disadvantage of the monolith is that it can lead to a one-size fits-all approach. Some parts of the application might benefit from being developed with other patterns and technologies, but the monolith makes it difficult to do. Let's have a look at a monolithic application. In the exercise files, you can look at the monolith in your editor of choice. I've got it open in Visual Studio. If we run the application, we'll see a dashboard. Now, if we click this URL, we'll see the website of a travel agency. We can list the tours, click on learn More button, and book a tour. When the tour has been booked, we can go back to our dashboard and check out the logs. We should see that there's a line about how we sent an email and how we made a call to an external API. These are just fake implementations. In a real application, we could call an SMTP server to send out a mail and an external API to notify another system of the booking. These are not part of our architecture. Now, if we query our database for the bookings, we'll see that the booking has been stored in the booking table. You can use your tool of choice. I'm using the free SQL Server Management Studio. Let's take a look at the code now. The project is organized into folders. Everything starts with a page. For example, here, we can see the tours page. It contains the UI markup to display the tours. In the code behind file, you'll find the code to load the tours. We're calling the GetTours method on the tours repository class, which contains the SQL code to retrieve the tours from the database. I've put these in the DataAccess folder. There's also a Domain folder, which contains our domain classes Booking and Tour. And finally, there's the Services folder, which contains our codes to call external services. Regardless of how the code is organized internally, this will all be compiled into a single executable. It contains the logic for the UI, the database, external APIs, sending emails, and business logic. The application can consist of multiple files, but they belong together and are deployed as a single unit to a server or workstation. Remember, the monolith may have a bad reputation, but a monolith is not synonymous with badly structured code. It's perfectly possible to build a clean monolith and let it evolve into other architectural patterns when necessary. This is something we'll cover in the chapter on modular monoliths.

### N-tier
- [Narrator] Let's take a look at what an N-tier or multi-tier architecture looks like. An N-tier architecture is an architecture that splits up the application into multiple tiers. A tier is a piece of the application that is responsible for a certain function and that can be physically separated from the other tiers. This makes them different from mere layers in a single executable application. The responsibilities in a multi-tier application are split up across technical boundaries, not functional ones. A typical N-tier setup is the three-tier architecture. A three-tier application consists of three systems, the presentation tier, which contains the UI and any logic that is pure UI logic. Then there's the business tier, which contains all business logic of the application, independent of UI or data storage technology. Finally, the data tier contains the database. These tiers can be installed on the same system, but they can also be on different physical machines, and because all sub domains are present inside a single tier, that shows that tiers are split up along technical boundaries, not functional ones. Usually data flows from one tier to another without skipping tiers. The N-tier architecture allows you to develop and deploy the tiers independently. The idea is that if something in the business logic changes, you only have to modify that single tier. In theory, each tier can also be scaled independently. However, in reality, things don't always pan out like that. Often a change in one tier requires a change in the other tiers. For example, a new field in a form will require changes in the UI, business logic and database. In the exercise files, I've added a sample N-tier application. You can run the application and you should see a dashboard. You can already see that there are two applications running. Let's click through to the presentation tier, and you should see a fictional travel agency website. We can list the tours, click on the learn more button and book a tour. This works just as we did in the monolith video. Now, if we go back to our dashboard and check out the logs, we'll see that there are two log lines for sending an email and calling an API of a travel agency. If we query the database, we can also see that our tour has been persisted. If we look at how the code is organized, we can already see that we have two applications, the business tier and the presentation tier. These are two of the three-tiers, the third one being the database. We are running everything on a single machine now, but we could deploy our tiers on different servers. Now, if we dive into the presentation tier, we can see that our tours page contains the necessary markup to display the tours, and in the code behind file, we can see that we're calling the business layer API to get the tours. This is a HTTP call over the network that the business tier receives in the tours controller. And in the tours controller, we can see that we call the tours repository to go to the database, retrieve the tours, and return it to the presentation tier. Our business tier is very basic, but in a real life application this tier would contain all the business rules and processes. The interior architecture has lost a bit of its popularity, but there are still many older systems that follow this pattern. That's why it's good to be able to recognize it and know how it works.

### Service-oriented
- [Instructor] Let's have a look at the service-oriented architecture. A service-oriented architecture is an architecture that consists of multiple services that each represent a business activity. Separate services may consist of other underlying services. Often, a service-oriented architecture will also include standardization of data contracts between services and an enterprise service bus. This requires a strong central governance of the architecture. This is what it could look like. There are multiple services that communicate with each other over the central enterprise service bus. The bus can handle multiple different messaging protocols. For example, when a product is requested, it always has the same structure regardless of who needs it. This is the standardized contract I mentioned earlier. The enterprise service bus will also contain business logic as to what should happen with the different messages. For example, duplicating events and routing it to the correct receivers. Service-oriented architecture gives us some flexibility in development and deployment because services are decoupled. This also makes them more easily scalable. In service-oriented architecture, business capabilities aren't duplicated across applications, but centralized in dedicated services. However, the centralized governance required for this architecture does mean we lose in team autonomy and agility. Many aspects of service-oriented architecture can be quite costly in terms of money, time, and effort, setting up an enterprise service bus or developing and enforcing standardized contracts, for example. Another disadvantage is that there isn't a clear view of what a true service-oriented architecture is or is not. I've created a simple example of what a service-oriented architecture could look like. You can find it in the corresponding exercise folder. If we start the application, you should see a dashboard just like in our previous videos. Immediately, we can see the different components like the tour service, the travel agent service, and the ESB, which is the enterprise service bus. Now, if we go to the website, we can create a booking. We'll see the different tours we can choose from, check out the details, and create a booking. Now, when we do that, our web application is requesting data from and pushing data to other services. Everything goes through the ESB. Now that our trip is booked, we can check out the logs, and if we use this filter we can see that we've sent an email and created a booking at a travel agency API. We can also query our database and see that our booking has been persisted. Let's jump through the code. When we want to see our tours, our tours page contains necessary markup to display the tours, and in the code behind, we see that we call the esbProxy to get the tours. If we go into that implementation, we see it's a HTTP call to our enterprise service bus. Now, let's check out our enterprise service bus. In this example, it's just a basic controller containing all the necessary hard-coded logic. In a real service-oriented architecture application, you would use a professional ESB product and configure it to route requests and messages to the right services. A true ESB can also map data structures, work with multiple protocols and much more. As you can see here, if we request the tours, we make a HTTP call to the tour service and return the results. The calling services don't need to know where the tour service is located or which protocols it accepts. In similar ways, every piece of communication goes through the enterprise service bus. When we make a booking, this is what happens. The UI sends a booking request to the ESB, which enters here, and it gets forwarded to the booking service. This stores the booking and sends another message back to the ESB, to the booking made endpoint. This message doesn't say what needs to be done. Rather, it represents the event that a booking was made, and the ESB then contains the business logic to notify both the email service and the travel agent service. There might still be a discussion on the exact definition of service-oriented architecture, and there are probably many different variations, but with this example, you now have an idea of the basic components and interactions in this architecture.

### Microservices
- [Instructor] It's time to dive into microservices. Microservices are a natural evolution of service-oriented architectures. An application is split up into multiple separate services that provide business functionality. Separate teams not only build the service, they're also responsible for running and maintaining it. For communication between services, a standard protocol like HTTP or a lightweight message broker is used. Unlike service-oriented architecture, the message broker doesn't contain any business logic. Because of the increased complexity of a microservices architecture, organizations will invest heavily in automation of testing, deployment, infrastructure configuration, and monitoring. It's important to zoom in on one of these points. The business activity of a microservice is more than just keeping track of data. It's also responsible for the business processes surrounding the activity. For example, an invoice service may be part of an e-commerce system. A simple implementation could make a call to the product service to get the names of the products on the invoice. But if the product service is down, the invoice service can't execute its business processes. This kind of a cascading effect so that the whole system goes down. However, if the invoice system has its own set of product data, it can continue working without the product service. This means that by focusing on business activities, you will probably need to duplicate some data throughout your system. Microservices have some great advantages. Services are independent of each other, making them more scalable. There's also no single team or service that acts as a central bottleneck, giving you greater agility. A high level of automation also reduces the chances of human errors and increases the reliability of your system. These advantages assume you've built your architecture correctly with all these aspects in mind, and that is one of the disadvantages. Building scalable, fail-safe microservices isn't easy and will require skilled engineers and an organizational and cultural change. It can be difficult to determine the boundaries of a microservice, and even if it's clear now, boundaries may change over time, requiring you to make complex changes to your system across multiple services. Microservices can also lead to complex communication patterns where the individual services are easy to understand, but the communication between the many components is not. In the Exercise Files, you'll find a basic example of a microservices architecture. To run the application, you can run it from Visual Studio. We can now navigate to our website and take a look at the different tours. If we click through, we can create a booking. Now, if we go to the database, we can verify that the booking has been persisted. And if we check our logs, we can check that we sent the email and sent an API call to a travel agent service. Back in Visual Studio, we can see our different microservices, each corresponding with our business functionalities. There's our website, our travel agent service, tour service, email service, and booking service. Each service also has a Docker file to automate deployments and execution. We can't go into the details of Docker here, but you can search in the LinkedIn Learning catalog for some great courses on Docker and containers. Notice also how the email's database has a tourist table. This is to ensure that if the tour service is unavailable, the mail service can still do its work, but it also means that we'll have to implement a system to duplicate some data and keep it up to date across your microservices. The core of microservices is that you have individual business services that communicate with each other through lightweight channels and that you automate as much as possible.

### Serverless
- [Instructor] Let's look at serverless architectures. Actually, a serverless architecture can take on two flavors. Backend-as-a-service is an architecture where you still have your own application in the traditional sense for your business logic, but you use third-party services for other concerns. These could be cloud services for authentication, logging and storage, for example. A function-as-a-service architecture consists of multiple pieces of code called functions that run in short-lived containers that are entirely managed by a cloud platform. These containers can't contain any state because they often live for just a few invocations. Just like the backend-as-a-service architecture, the functions integrate with many cloud provider services. For the remainder of this video, we'll be focusing on the function-as-a-service variant, as it is what is most commonly understood as serverless. A serverless architecture has several advantages over more traditional architectures. First, serverless applications scale very easily. If there is a peak in requests, the platform can automatically spin up new instances of your functions. Because many parts of your applications and its infrastructure are managed by the cloud platform, you have less infrastructure to manage as well. And because a new function is so easily written and deployed, it's very easy to experiment with new IDs. There are also disadvantages to serverless architectures. When you choose a specific vendor, you'll have to work with the constraints that they enforce. For example, a vendor might stop supporting a version of a framework you're still using. It also won't be easy to switch vendors. Developing a serverless application is also very different to what many developers are used to. One example of this is that your functions should be stateless. For example, if a client modifies something in memory, you can't be sure that another invocation or another client will run on the same instance. Serverless functions also suffer from a concept called cold starts. This is where the first invocation of a function takes slightly longer because the platform has to spin up a new container. Once it is running, however, subsequent invocations will perform better. And finally, while proponents of the serverless architecture may argue that it's cheaper, this really depends on your use case. Most cloud providers charge according to the resources you use, but it can be quite difficult to calculate the expected use upfront. To see an example of a serverless architecture, take a look at the serverless folder in the exercise files. This application consists of two Azure functions, a sender and a receiver. Luckily, we can run them entirely on our local machine. First, in the HTTP file in the sender project, let's first send a HTTP request to our sender. In the log of the receiver, we can see that we received the message. Now, what does this look like internally? Both functions are just a single file as you can see here. Here's the booking function, and in the receiver, we have our bookings processor. The sender is triggered by a HTTP request and put something on the queue. And on the receiving side, you can see that it is triggered by a queue trigger. Of course, this is a very simple application, and you could split a more complex application over more files, but the infrastructural side of the code is much simpler than in traditional applications.

### Distributed systems
- [Instructor] Let's take a step back and consider distributed systems. We've covered service oriented architectures, microservices, and serverless, these are examples of distributed systems. The user experiences the application as a single system, when in fact it's built from many different applications. A first important consequence of distributed systems is the risk of losing transactional integrity. This is the idea that we must ensure our data remains consistent after a user action. Here's an example, when a user submits a form in a monolith, we can update multiple database records in a single database transaction. When a table causes an error, the transaction is rolled back and nothing is modified. If there are no errors, all tables are updated, it's all or nothing. Now, let's take this example to a microservices architecture without transactional integrity. If two services update our databases, but a third one fails, our data can lose its consistency. We can't use a single database transaction because we're using different running processes and even different databases. There are different ways to solve this. For example, the saga pattern ensures that the stored data is reset to its previous state with what is called a compensating action. But what if a service is down? Direct HTTP calls won't reach it, causing a rippling effect throughout our system. An interesting pattern is a transactional outbox pattern. In this pattern, a single service modifies its data, but also stores a message in the same database transaction. Then, there's a separate piece of logic that regularly processes any unsent messages. This way, the sender can be sure the receiver will eventually receive the message. Using a message broker instead of direct HTTP calls can also help out by making our communication asynchronous. Once the service comes back up, it can process all messages in the queue, and sending surfaces can be sure their messages will eventually be processed. Another consequence of distributed systems is that your data will often be duplicated. This can be quite jarring for developers used to a certain way of working. If you have an invoicing service, for example, and it needs a customer's address, you could query the customer service every time, but again, if the customer service is unavailable, this service can't perform its work. It's better to duplicate the customer address inside the invoicing service so it can perform its work independently. If the address changes, just send a message from one service to the other and update accordingly. With all this messaging going on, you'll need to clearly define the structure of the messages or what's called the contract. If a contract changes, receiving services need to know about this change, so the code can be updated as well, which also means, you need to avoid breaking changes or at least introduce them in a phased manner so every team has time to update their code. In this video, I've only briefly covered transactional integrity, duplication of data, and messaging. There are many more challenges that come with distributed systems. But there's no need to panic, just be aware of them and read up on these architectures before you start implementing them, your distributed systems will only benefit.

Saga Pattern
Transactional outbox pattern 

### Peer-to-peer
- [Narrator] Now we're going to take a look at the peer-to-peer architecture. The peer-to-peer application is a special case in our catalog of software architecture patterns. Peer-to-peer applications are a network of applications that communicate with each other without a central server in between them. The individual applications don't have to be online all the time. They can connect and disconnect as they please. This means they need a way to discover each other because they might not have fixed URLs or IP addresses. As you can see in this diagram, the communication goes from one machine to another directly. In a closed network, the machines will be able to find each other easily. This isn't the case in a large network like the internet, which is why sometimes a central server is added. Each machine can notify the central server that they are online, after which the central server can notify the others. Then, the direct peer-to-peer communication can continue without the central server. Peer-to-peer applications serve a specific purpose. They're ideal for applications that want to share their resources, like processing power, data, memory, or storage. Because there's no central server, they can be cost-effective, especially if your organization doesn't have to run all the individual clients. Scaling the system is also easy. All you need to do is add more applications or machines to the network. There's no extra configuration necessary, and often people already have a machine available, so there's no need for expensive server purchases. But, peer-to-peer applications have their drawbacks. Because the system is so decentralized, there are potential security issues. For example, in a data sharing network, viruses can transfer more easily. Or in an application that distributes calculations, some corrupt nodes in the network might spread incorrect results. And let's not forget that peer-to-peer applications only lend themselves to specific scenarios, therefore sharing resources, which is why most of us will probably not encounter such an architecture in our professional work.

Q: You are updating the UI tier of an N-tier system. What additional updates, if any, are probably required?
A: You may have to update the business logic and data tiers.

Q: Why would you consider a monolithic architecture over other architectures?
A: It is easy to understand, implement, and test.

Q: You and your development team are tasked to deploy a peer-to-peer (P2P) system for a new multiplayer game. Why should you consider adding a server just for the P2P system?
A: to assist with notifying the network of new machines that come online

Q: When should you consider using a function-as-a-service serverless architecture?
A: when you have a number of functions you need to run that can be hosted on a third-party platform

Q: How does a microservice architecture fundamentally differ from a service-oriented one, and what advantage does this provide over service-oriented architectures?
A: Services talk directly to each other, which increases agility.

Q: Your team is considering a service-oriented architecture. Why is choosing this architecture over other architectures advantageous?
A: It is more easily scalable than some other architectures.

## Application Patterns

### Layered
- [Instructor] The layered application pattern is a classic pattern that you'll encounter often in various forms. A layered application is an application that has several layers. Each layer has distinct responsibilities. The idea behind the layered application is that calls in the code flow downwards. A layer can call the layer below it, but not above it. There are five layers that occur often. The presentation layer contains the user interface. The application layer is the layer that receives calls from the UI and translates them into calls that the business layer can understand. The business layer contains all the business logic, and the persistence layer is where we put the code that knows how to interact with the database. Finally, the database is where we store the actual data. If necessary, you can add more layers, like a caching layer, for example, or in some scenarios, two layers can be merged into one. The layered architecture is well-known among many developers, and it's also an easy way of organizing the code in your application, but there can be some significant drawbacks to layered applications. They tend to lead to highly coupled code that becomes hard to maintain. The layered pattern often requires us to write a lot of code to pass data from one layer to another, where no value is added in the intermediate layers. Because the application is split up across technical boundaries, it's difficult to take a specific business functionality and split it off into a new application. In the exercise files, I've created a simple example of a layered architecture application. You can start it from Visual Studio or the command line, and you'll see a dashboard. Once everything is running, we can navigate to our website, and you should be able to see a list of tours and create a booking. So here we go with the list of tours. If we click on learn more and book now, we can create a new booking. Now, this application behave just like the application that we saw in previous videos. Back in Visual Studio, you can see how the application is structured in the solution explorer. I've put everything in solution folders because Visual Studio would list the layers alphabetically, not from top to bottom. So at the top, we have the presentation layer, which contains our UI markup. For example, here we have the booking page with its HTML, and in the code behind, we can see that if we want to create a booking, we create a new booking object and call the save method on the bookings controller. The bookings controller is an object that lives in the application layer. The bookings controller will map the booking from the application layer to a booking from the business layer and then call the booking service, which lives in the domain layer or the business layer. As we can see, the booking service contains the business logic to call the bookings repository to save our booking to the database, and also retrieve the tour and send a confirmation mail and notify the travel agency. And the bookings repository and the code for calling the external APIs lives in the infrastructure layer. For example, here we can see the bookings repository. So as we can see, all calls go downwards, so that's the structure and flow of data in a layered application. I've shown you a monolithic system, but it would be perfectly fine to have a layered application be part of a larger system, like a service-oriented or microservices architecture.

### Onion
- [Instructor] In this video, we'll take a look at the onion architecture and the difference with the layered architecture. In an onion architecture, you start with your domain model. This contains the classes with their properties and business logic. Around that we have domain services. These are interfaces the domain needs, but doesn't implement. Usually they're infrastructural concerns like data storage. Going further, we find the application services. These are the services containing business logic that spans over multiple domain models or domain services. They're invoked by either the user interface or automated tests. And finally, we have a layer providing the implementation of the domain services called the infrastructure layer. As you can see, we end up with the diagram that somewhat looks like the layers of an onion. Hence the name. Each outer layer knows about the inside layers. This means that our application core is ignorant of any infrastructure or user interface concerns. Then how does that differ from a classical layered architecture? Well, we can clearly see a difference in the relationship between the business and the persistence layer, for example. In the layered architecture, the business layer points to the persistence layer. But in the onion architecture, the direction is inversed. This means that the inner layers define the interface they need, but an outer layer implements the interface. For example, the business layer will define the interface for a repository, but the implementation containing the SQL queries will be in the outer infrastructure layer. This is what we call the dependency inversion principle. Traditionally, the interface and the implementation lived in the same layer. The dependency inversion principle puts the interface next to the consumer and lets the implementing layer reference the defining layer. One of the onions primary advantages is that the business logic layer is completely decoupled from any other concerns, making it easier to write automated tests. Like the layered pattern, it's conceptually fairly easy to grasp and implement. But if it's applied to a bigger system with multiple business functionalities, it can lead to a large and complex code base over time, even if the architecture itself isn't complex. Also, the developers must fully grasp the dependency inversion principle, which may not always be the case. The exercise files contain an example of an onion architecture. If you run it either from visual studio or from the command line, you'll see the website for the fictional travel agency, which we've been using in previous videos. If we look at the code, we can identify the different layers of our onion. But the interesting bit is here, the interface for the repository is defined in the domain services layer, but the implementation is in the infrastructure layer. You can compare this to the example of the layered architecture where both the interface and the implementation of the repository are located in the persistence layer. So while the layered architecture and the onion architecture look very much the same, they differ in that one crucial aspect of the dependency inversion principle.

### Ports and adapters (or hexagonal)
- [Instructor] Now it's time to explore the ports and adapters architecture, also called the hexagonal architecture. Like the onion architecture, the core module is the business logic or the domain. This core then defines the interfaces it needs to interact with the outside world. These are called the ports. Finally, there are specific implementations that use or implement these ports. We call those the adapters. The pattern distinguishes between primary and secondary adapters. Primary adapters drive the application, which means they make calls to the domain. Secondary adapters, on the other hand, are driven by the application, meaning they get called by the domain. As an example, a primary adapter could be a user interface, console application, or unit tests. Examples of secondary adapters are blob storage clients, SQL server repositories, or even fake implementations for the unit tests. You may think that this doesn't differ a lot from the onion architecture, and you're right, but the ports and adapters pattern emphasizes that each adapter is put in its own module. There isn't a single infrastructure layer, each adapter lives on its own. And unlike the onion architecture, it doesn't prescribe how the inside of the application core should look like. Again, the advantages are loose coupling, which means easier testing, and it should also help in reducing complexity. But, like the onion architecture, there is the potential for a monolithic system, and developers should be aware of the dependency inversion principle required to implement the pattern. Now let's take a look at the code. Again, this application is a fictional travel agency website just like in the previous videos. As you can see, we have three secondary adapter projects, one for the email, one for a travel agent API, and one for persistency. If we look at the persistency, we can see that the bookings repository implements the Ibookings repository, which lives in our business core. If we look at the colors of the booking repository, we see that it's the booking service in the domain, which means that the booking repository is actually a secondary adapter. Our user interface calls the domain, as we can see here. This calls the tour service, making this a primary adapter. The ports and adapters pattern is an architectural pattern, loved and recommended by many industry leaders and experts. So I also recommend you learn and use it.

### Differences between layered, onion, and hexagonal
- [Presenter] The layered, onion, and ports, and adapters architectures look very much alike, so it's worth taking some time to explore the differences. Let's start with the layered pattern. As you may remember, layers make calls downwards on the architectural diagram. Apply the dependency inversion principle and your business logic or domain layer is now at the center of your diagram, and this gives you the onion architecture. If we compare the layered and onion solutions in the exercise files, you'll see that in the layered architecture, the business project references the infrastructure project. But in the onion example, it's the other way around. Here, the infrastructure references the business layer. Digging deeper, we can see that in the layered architecture, the interface to store bookings in the database is defined in the persistence layer. In the onion architecture, it's defined in the domain services. Now there are those who say that the difference between onion and ports and adapters is the fact that adapters live in their own module, while they all live in the same module in the onion architecture. This isn't necessarily true, however. A single layer in the onion architecture may consist of multiple modules. In fact, it's probably better that it does. In the exercise files, I purposefully wrote the onion architecture with all infrastructural logic in a single module. If we compare it with the ports and adapters example, the difference is that in the latter, infrastructural logic is split over separate projects. But there's more. If we compare the domain in the onion to the domain in the ports and adapters architecture, we can see that the ports and adapters architecture doesn't define what the core domain should look like. The onion architecture is more opinionated. It defines application services, domain services, and a domain model. But generally, you will end up with a similar architecture. In essence, the main difference is the shape of the schema. As you see here, the modules are the same, it's just the way the boundaries are drawn that differs. Authors like Mark Seaman and Jeffrey Palermo have in fact pointed out that they are the same. The onion architecture may focus a bit more on the different layers, where the ports and adapters architecture doesn't really dictate what the core of the application should look like. So while they have a slightly different focus, both onion and ports and adapters are the layered pattern with the dependency inversion principle applied.

### Modular monolith
- [Narrator] In this video, we'll be covering the modular monolith. As the name implies, a modular monolith is a monolith. It's a single running process that can be deployed as a single entity and usually handles all concerns of the system. This means it contains multiple subdomains for the business, and it contains different technical concerns like user interface, business logic, and data storage. In the video on monoliths, we learned that they risk becoming overly complex with a lot of tightly coupled code. This is what the modular monolith aims to solve. In a modular monolith, we try to use the concept of microservices but packaged in a single executable. Specifically, we would create separate modules with our own architecture, but keep it inside a single running process. Another way to look at it is that instead of splitting our application along technical boundaries, we split it up along business boundaries, but inside each business component, we should still apply good architectural principles. Of course, modules still need to communicate with each other. Just like in microservices, we could use some sort of message broker. This could be an in-memory messaging system or a real message broker running somewhere else. Each module should also own its own set of data as integrating over database tables is considered bad practice. Modular monoliths give us the advantages of microservices, like loose coupling and increased agility. Each module could be developed by a separate team. What it has over microservices is that it's easier to run the application on a developer's machine. All the code is there together, so there's no need to pull in another team's code and get that running. It also has an easier deployment model. There's one application to compile and deploy, and finally, if you do need to split off a module into a separate service, it will be easier than in a traditional monolith because it will split up along business boundaries. Beware though that the modular monolith requires some discipline so that we don't cross boundaries where it's not allowed. And teams do lose some autonomy regarding which technologies to use and when to deploy. Finally, it's still a different way of developing software for many. Developers should be aware of things like data duplication, transactional integrity, and eventual consistency, which we covered in the video on distributed systems. In the exercise files, you can find an example of a modular monolith. It's the same application of the fictional travel agency we've used in previous project, but let's look at how it's structured internally. In the main application, open the program.Cs. Here we can see it registers services from different modules and calls the startup logic for each one of them. They're hard-coded here, but you could also discover the modules dynamically at runtime. Each module is responsible for all the components it needs to function properly. It contains data access logic, business logic, and user interface components. If we look in the pages folder of the main application, we can see that there are no pages for bookings or tours. These are contained in each module. For example, in the bookings module, you can see we have the booking.cshtml and BookingConfirmed.cshtml pages. Also, in this module, we can find the domain classes, the repositories for data access and a service containing business logic. In this case, all we do is store the booking and publish a tour booked message so other modules can act accordingly. For example, in the travel agent module, there's a travel agent notifier class, which mimics a call to an external API. Both modules have no notion of each other, which is also why we've set the access modifiers to internal meaning each module only has access to its own classes. This ensures our separation of concerns. In this example, each module is a single C# project, but you could create modules that span several projects. In that case, or for unit tests, you would need to expose the internal classes only to those specific projects. In C#, we can do that with the internals visible two attributes. For example, in the bookings module, we've added this so that our bookings module tests have access to the bookings module classes. The modular monolith is a powerful architecture because it clearly separates business functionalities while still being an approachable architecture for many developers.

### Microkernel
- [Instructor] The microkernel pattern is an interesting one. It's also called the plugin pattern. In this pattern, the application consists of a piece of core logic that can be extended with plugins. The core defines the contracts that the extensions need to adhere to, but other than that, the core doesn't need to know which extensions exist or how they're implemented. Great use cases for this are task schedulers, workflows, or data processing applications. But you can also see this pattern in browser extensions or plugins for graphic design applications. The microkernel pattern offers the advantage of great flexibility. You don't need to know the required features upfront. They can be added as extensions later. The extension implementation is also clearly separated from the core logic. This allows separate teams to work on the core logic and the extensions at their own pace and in their own style. Some implementations will also allow you to add and remove extensions without restarting the core. But a possible risk is that it's impossible to know if the core API will be sufficient for all future plugins. The core must also trust the extensions. It's possible that an extension corrupts the entire application. And finally, it might not always be clear what should be in the core and what should be in the plugin. In the exercise files, I've put a sample application of what a microkernel architecture could look like. It's a fictional processor of bookings with two plugins. You can compile the application by running the build-all scripts. Next, execute the application with the run scripts. As you can see, it can't find any plugins. If we go to the plugins directory, indeed it's empty. In another terminal, we can run the copy-explorecalifornia plugin to copy the plugin. You can see in the directory, it now contains the plugin, and if we look at our running application, we see it retrieves three bookings from one source. It will always be three bookings because I've hard coded this in the plugin. Now, we'll also copy the hotellandon plugin, and immediately we see it retrieves four bookings from two sources. Back in Visual Studio, we can see what this looks like. We have our IInputPlugin interface, which our plugins must implement, and in Program.cs, we can see the basics of a microkernel. First, in the plugins directory, we find all the DLLs. Then using a NuGet package, we load these DLLs and find the implementations of the IInputPlugin interface. Finally, we loop over the implementations and call the GetBookings function. The plugin architecture is a useful architecture, but with the advent of microservices and the asynchronous messaging, it has become easier to extend existing applications without modifying the core logic. Nevertheless, it's useful to know how the microkernel pattern works.

### CQRS
- [Instructor] Let's take a look at the Command Query Responsibility Segregation pattern. Command Query Responsibility Segregation, or CQRS, is a pattern where we have two entirely separate models in our application. One for reading data and another for writing data, where all the business logic is located. When the UI sends a command to the application, the write side will work the way we're used to, retrieve data from the database, modify the model in memory while going through the necessary business rules, and then send the modifications back to the database. But then something new kicks in, the system will send the necessary modifications to the tables on the read side. Several records or tables on the read side will need to be updated, so data is synchronized with the write side. Now, when the UI wants to display some data, the read logic retrieves it from the read tables with a simpler query that will be necessary on the write side. Yes, this does mean data is duplicated in our database, and as you can see in the diagram, you could even use two separate databases. CQRS is often implemented together with event sourcing, but it doesn't have to be. We'll be covering event sourcing and the combination of the two later in this course. One advantage of CQRS is that your read queries become simpler. This also allows you to make them faster and more scalable. Finally, thinking in terms of commands and queries maps naturally to the business language. This makes it easier to communicate with stakeholders. But CQRS isn't a good fit for every project. Very simple applications that are just a user interface over a database don't always need the complexity of the CQRS pattern. Even though CQRS in its simplest form isn't too difficult, it does require a slight mental shift from some developers. And you also need to ensure you synchronize the two models. This means there is the possibility that the read data gets out of sync with the write side. And even if the synchronization works perfectly, there might be a small delay between the update in the write database and the update in the read database. Eventually, the data is in sync, but not immediately. This is called eventual consistency and can be something to take into account. For example, the UI might not be updated immediately after the user made the change. Let's have a look at the CQRS example in the Exercise Files. In the Domain folder, you can see that I've created a ReadModel and a WriteModel folder. If we take a look at the tour classes, we can see that they are identical, but the booking class in the WriteModel, for example, has a Tour property while the BookingOverviewItem in the ReadModel just has a Tour name property because we don't need the entire tour model on the read side. In the DataAccess folder, you can see the same split between the Read and the WriteModels. If we take a look at the BookingsRepository on the write side, you can see that when we save a booking, we also publish a tour booked message. This uses a library called Mediator. This allows us to write a handler that handles the message. The BookingOverviewItemGenerator is such a handler. As you can see, it handles the tour booked message by creating a new booking overview item on the read side. This way, our booking repository doesn't need to know which classes need to be called to update the read model. Now, let's run the application. Like in previous videos, we can click through from the dashboard to open the user interface. If we click through to the list of tours, we can open the details of a tour and create a new booking. Now, if we query our two tables, you can see that on the write side in the booking table, we have a record with the TourId. But on the read side, in the BookingOverviewItem table, you can see we have a record with the tour name. This BookingOverviewItem table will allow for faster reads because no joins are necessary. You may now wonder isn't this unnecessary complex? And yes, in this example it is, but many applications have very complex database queries to just show the user a screen with all the necessary data. Having the traditional write model with all the necessary checks for consistency, but also a read model to easily query a single table for visualization can really improve the performance and user experience of your applications.

### Event sourcing
- [Instructor] In this video, we'll dive into event sourcing. In event sourcing, instead of storing the current state of our data in the database, we store the events that happened to our data. An event is defined as something that occurred in the past. If you want to know what the current state is of a certain entity, you apply all previous events to a new object. This is called rehydration or event replay. An example can clarify things. Traditionally, we retrieve a record from our database, for example, a customer with the name Amina, then we update the name to Sophia and store that value in the database. There's no trace of the original name. In event sourcing, we could see two events, a first one indicating a customer with the name Amina was created, and the second indicating the name was changed. To get the latest version of our customer, we replay these events and end up with an object representing our customer named Sophia. A great advantage of event sourcing is the trace you build up for each entity. You can see exactly what happened to an entity, and with some extra metadata, you can build an audit trail, which gives you insight into when events occurred and who or what triggered them. Speaking in terms of events, also maps to the business language, making it easier to communicate with stakeholders. Finally, if there is a bug in the handling of an event which leads to a wrong state of an entity, we can simply fix the bug in the event handler. The next time we replay the events, our entity will be in the correct state, and there's no need to manually fix the data. But event sourcing definitely has its challenges. If your events lead to updates in external systems, you should be aware that replaying the events could lead to issues in those systems. You'll need a way of knowing if the events are new events or just part of a replay. Changes to the code of events or event handlers can also be tricky. If you add, remove, or rename a property in an event, your database still contains the events in their old form, and so your code should be able to handle this, and another challenge is when you have a large amount of events that take some time to replay. This can make the application slow to load objects from the database. You can solve this by storing snapshots of the object at a certain point in time, and then use that to replay any newer events, but that, too, isn't trivial to set up. So how do we implement event sourcing? When we retrieve an object from the database, we'll actually retrieve the persisted events and replay them in an object. The class contains code that reacts to the events so that the correct state is restored. Then, when we make a method call on the object, we'll just add a new event and let the object handle it so that its state is updated. When we want to save this object, we'll save all the new events to the database. Then we can also pass the events to any matching event handlers. These could be responsible for calling an external API, sending an email, logging something, and so on. Now, let's run through some code to see this in action. In the exercise files, you can open the event sourcing solution. I've already added some interesting breakpoints, so let's start debugging. From the dashboard, I'll navigate to the website. Next, I'll go to the list of tours, click on the learn more button, and create a new booking. So here in the user interface, we call the constructor of the booking class. In the constructor, first, we register the methods that handle certain event types. Then, instead of setting the necessary properties, we just create a new tour booked event and call the update method. The update method calls the necessary event handlers, and it's those handlers that set the actual properties. The update method will also add the event to the list of pending events. Now, when we want to save a booking, we first serialize the pending events to JSON and then store it in a single table for all events. As a final step, we call any necessary event handlers that need to perform actions based on events, like this travel agency notifier. When we want to cancel a booking, we need to retrieve it again. We do so by retrieving all events for that booking, then deserializing the JSON and passing them on to a new instance of the booking class. This will then call the necessary handling methods in the class to restore the state, for example, our on tour booked method, and once we have the object in its latest state, then we can cancel the booking, and the whole mechanism is repeated again. Event sourcing is an entirely different way of dealing with data, but a powerful tool in your tool belt of architectures.

### Combining CQRS and event sourcing
- [Instructor] Let's see what the combination of CQRS and Event Sourcing would look like. The terms CQRS and event sourcing are often used interchangeably, but they are fundamentally different. And even though one can be implemented without the other, the combination can be very powerful. We'll start with an event sourced application. Our entities are built by replaying events on a new object. That's how we restore the state of an object. When we want to alter the state, we add a new event and handle that event. When we persist events, we can trigger event handlers to perform actions on other objects or systems. To add CQRS to the mix, we want to separate our read model from our write model. In our event sourced application, the whole system of events and handlers is our write model. To add a read model, all we need to do is make event handlers that populate the read model. Then we can add the necessary code to query this read model. Combining CQRS and event sourcing gives you the best of both worlds. The advantages of event sourcing, were having another trail of which actions were executed on an object, and being able to use the language that the end user uses. Adding CQRS means we don't need to replay the events to display data to a user, and it scales better. But combining these two patterns also means you have the downsides of both. There are more components that interact with each other, making it slightly more difficult to learn. Because of the CQRS pattern, your read model can become out of sync with your write model. Also, when you want to change the structure of an event, for example, by renaming a property, your code needs a way of handling this correctly because the events stored in the database will still be using the old property name. So let's see this in action. In the exercise files, you'll find the fictional travel agency web application we've been using throughout this course. For the end user, it still behaves the same, but let's look under the hood. I've added a breakpoint in the booking overview item generator. It's an event handler in the event sourcing architecture, and it's responsible for creating a read model in our CQRS architecture. We'll now start debugging the application. Like in previous videos, you'll get a dashboard where you can navigate through to the website. Let's navigate to the list of tours, select one, and create a new booking. Now our event sourcing system has done the necessary work to store the events of the new booking, and because of that, the event handlers kick in, they can call external APIs, send an email, and in this case, update our read model. So if I just continue and we'll check our database, we can see that a record has been added to the event table, and also in the booking overview item table, a record has been added. This record can then be used to easily populate an overview of bookings in the user interface without the need to join to other tables. So when should you use event sourcing or CQRS and when should you combine the two? First, don't use it for simple domains that have no need for the advantages of these patterns. If you decide event sourcing could be useful for you, start with event sourcing without CQRS and add CQRS later. It's harder to modify your architecture for event sourcing than it is to add CQRS.

Q: Why should a developer consider adding CQRS to an event sourcing architecture?
A: It can make the event sourcing queries much less complex when including CQRS.

Q: How is using event sourcing beneficial?
A: It is possible to build an audit trail that shows when an event occurred and what triggered it.

Q: Why is there always the possibility that data in a CQRS system may be out of sync?
A: The read logic and write logic are separated, sometimes leading to asynchronous behavior.

Q: How can using a microkernel architecture be disadvantageous?
A: The core API might not fit future plug-ins.

Q: Why should you consider using an architecture other than a layered architecture?
A: Layered architectures can require a lot of code to pass data between different layers.

## UI Patterns

### Forms and controls
- [Instructor] The Forms and Controls pattern is a well-known pattern, but not necessarily under that name. In fact, it doesn't have a well-known name at all. I took the name from Martin Fowler, a well-known software developer and author of several books on architectural patterns. On the user interface side, this pattern basically consists of two components. One piece is the code that defines what the UI should look like. This can be a markup language, like WPF's XAML, or a more general purpose language, like C# or Java. Sometimes the framework vendor has created a drag-and-drop designer to make it easier to create the user interface. The second piece of code is code that controls the interactions with the user interface. This is sometimes called the code behind, because it's code that lies directly behind the user interface. Events are raised when users enter text in an input control or click a button, for example. The code behind can then change the state of other controls or take more sophisticated actions, like sending data to a server or database. This architecture works very well for desktop or mobile applications. It's a very simple pattern that allows developers to quickly get a working application. This also makes it ideal for proof-of-concept apps. But as the system grows, the code behind files become more complex and often bloated with business logic. To make matters worse, this code is often very difficult to run in automated tests, if not impossible. This means developers need to test everything manually. And when you have a large system with many business rules, things can get overlooked easily and bugs creep in. Here's an example of an application built with the Forms and Controls architecture. It's a simple Avalonia application, meaning you can run it on Windows, Linux or Mac. So here's the booking screen. As you can see, it contains the XAML code that defines where elements should be placed on the screen. We can also see there is an almost identically named file, which is our code behind file. And here we can see that the views loaded event is handled by getting data from the database through our bookings repository. We can also see that we're handling the click on the booking button. This ties this logic to our user interface and makes it difficult to run in a unit test. So while Forms and Controls is good for simple and small apps, we want a more decoupled approach where we can test more of our code. As we'll see in the next chapters, there are better architectural patterns to achieve this.

### Model-View-Controller
- [Instructor] The Model-View-Controller pattern, or MVC, is a user interface pattern invented in the late '70s. In MVC, there are three distinct responsibilities. The model, the view, and the controller. The model is where the data of the application is managed. It receives input from the controller. The controller is responsible for receiving user input and passing it to the model in a way that the model will understand. Finally, the view is responsible for presenting the model to the user. The MVC pattern is a great pattern for the web. The browser sends input to the controllers and receives views to display to the user. The advantages of an MVC pattern are a clean separation of concerns. This means that the three components have clearly defined responsibilities. It also enables developers to work on these separate concerns in parallel. For example, one developer could be writing the view, while another works on the model, and yet another finishes the controller. And because the UI design and the logic behind it are decoupled, you can write unit tests to test the logic and even create different views that work with the same controller. Finally, it's a well-known pattern that you'll see often in many web frameworks, although it can be applied to desktop or mobile applications as well. There is some risk of ending up with bloated controllers though. If we put input validation, business rules, and data access in our controllers, they'll become difficult to manage. In the exercise files, you'll find the web application that we've been using throughout this course to show system and application architectures. If we now look at the UI part, we'll see the three main components of the MVC pattern. There's a folder for the views, the controllers, and the model. In the views folder, you'll find the HTML markup that is rendered in the browser. In the models folder, you'll find our classes that we use to represent the data. Finally, in the controllers, you'll find the controllers that receive the browser requests. These controllers don't contain a lot of complex logic, but you can already see how they could become bloated. All we're doing is connecting to the database and retrieving data. But once you add validation and business logic, things can easily get out of hand. That's why the MVC pattern is a UI pattern only. To achieve a good architecture, you'll have to combine it with one or more other patterns. In this example, the MVC pattern is the UI part of an onion architecture. The views and controllers live in the UI layer, and the model could be found in the domain layer. But because we have our application services, domain services, and infrastructure layer, our controllers can be more lightweight.

### Model-View-Presenter
- [Instructor] The Model-view-presenter pattern, or MVP, is an evolution or variation of the model-view-controller pattern. In MVP, again we see three important components, the Model, the View, and the Presenter. The user interacts with the View, which passes on commands or events to the presenter. The presenter then manipulates the Model and tells the View which data to display and how. There are two variations of MVP. If all the UI logic is in the Presenter, we call it Passive view. On the other hand, the UI could contain all the necessary details on how to render the data, and we would use the Presenter for more complex logic. This is called Supervising controller and is more common these days because the current state of UI technology and markup languages allows us to put quite a bit of logic in the UI. Just make sure it's UI logic and not business logic. The MVP pattern is a great pattern for desktop or mobile applications. Instead of making your user interface manipulate the data directly, you have a clean separation of concerns between the UI, the presenter logic, and the domain model. This also makes parts of the application easier to test. Just like in the MVC pattern, you have to watch out for your presenters becoming too big. Also, if your platform supports it, the MVVM pattern is a more powerful option. Still, it's good to know and recognize the Model-view-presenter pattern when you see it. You can find an example of the MVP pattern in the exercise files. It's an Avalonia application, which allows it to be built and run on different platforms. The application also behaves just like the one in the Forms and Controls video, but internally we'll see some differences. If we look at the bookings view, you can see it creates the new bookings presenter in the constructor and passes itself to the bookings presenter. In the bookings presenter, we can see that it only accepts an interface, the IBookingsView. This allows the presenter to be technology agnostic. We could, for example, write a similar view in WPF instead of Avalonia. Our bookings presenter reacts to events fired by the view, like this ViewLoaded event. It can then do the necessary actions and queries to the model. Here, we retrieve the data from the database and pass it back to the View. If we look at the LoadBookings method, we see that we're setting the item source property of a data grid and letting the View do the rest of the UI logic to display this data, so we could say this implementation has a bit more of the supervising controller flavor of MVP. For example, with the passive view, we can look at the booking view. This view has no notion of the model at all. It only exposes the setter methods that accept basic types. You can imagine that this can quickly become very verbose as views become more complex.

### Model-View-ViewModel
- [Instructor] MVVM or model-view-viewmodel is the last of our UI architecture patterns. In MVVM, we have three separated components again. The Model, the View, and the ViewModel in between. The model contains our business logic and data, and the ViewModel interacts with it. The special part here is that we connect the View to the ViewModel by using the advanced data binding techniques that the platform provides. This means communication between the ViewModel and the View is done by the framework, and our ViewModel has no link to the View at compile time. This allows us to write a lockless code as we'll see in the demo app. The last step to show here is the user interface interacting with the View. Thanks to two-way data binding the user's actions are passed onto the ViewModel and any updates in the ViewModel are seamlessly passed back to the View. The MVVM pattern is a great pattern for desktop and mobile applications if your platform supports the necessary data binding techniques. With MVVM, just like MVP, you can achieve a clean separation of concerns, which also makes the application easier to test and create different views for the same ViewModel. While MVVM is a powerful pattern, it's can be overkill for simple applications, and the data binding can be harder to debug. If some piece of data binding doesn't work, you may have more difficulty figuring out what is wrong exactly. In the exercise files, I've put an example of how an MVVM application could look. It behaves exactly like the application in the forms and controls and MVP video, and it's also built with the Avalonia UI framework to enable cross-platform compatibility. In Visual Studio's Solution Explorer, you can already see the three main components of the MVVM pattern. There's a folder for the Model, one for the ViewModels, and one for the Views. Let's look at the main window. In the code behind, we set the DataContext to a new MainViewModel. Then in the markup, we use data binding. In the case of Avalonia and XAML, this is done by this syntax. this is done by this syntax. Content ="{Binding MainContent}". When we look at the MainViewModel, we can see it contains a property called MainContent The RaiseAndSetIfChanged method is part of the reactive UI framework, which greatly simplifies writing an MVVM application with Avalonia. What it does is raise an event so that the data binding system knows it has to update the content control in the markup. Notice how we don't pass our view to the ViewModel. We can't cover the ins and outs of the data binding system here, but let me show you just one more thing. The BookingsView contains a data grid, which is bound to a bookings property. If we look at the BookingsViewModel, we see it has a collection of BookingViewModels. If we look at the App.axaml file, we've also defined a DataTemplate for this ViewModel. It points to the booking view, and if we look at the BookingView, we can see it looks different than the row of a data grid. Let's see this in action. If we click on the booking link, the grid is loaded in the main content and each row is a representation of a BookingViewModel. If we click on a link, we get another representation of that same ViewModel, so we've created multiple Views for the same ViewModel.

### Differences between MVC, MVP, and MVVM
- [Instructor] Now that we know what MVC, MVP and MVVM are, let's take a look at the differences. The goal here isn't to be pedantic or purist, but rather, we want to be able to understand the differences, know the intention of each pattern, and follow its guidelines when we're working in a specific architecture. So here are the differences. First, there's the underlying technical concern of which component catches the user interaction. Is it a view like an MVP and MVVM? Or is it a controller like an MVC? Another difference is the amount of code in the UI, often in a code behind file. In MVP, the view needs to be aware of the presenter, so it can pass on commands and events. In MVC and MVVM, the view could be pure markup or contain only pure UI code. This also reveals a third difference. How aware is the view of the underlying model? In MVC, the view binds to the model. In MVP, it depends on the flavor. In supervising controller, it's okay for the view to know the model. In passive view, the view has no notion of the model. And in MVVM, the view usually isn't aware of the model, only the view model, which acts as an in-between. A last key difference is the concept of data binding. The passive view flavor of MVP will contain no, or just minimal data binding. In MVC and MVP's supervising controller, there will probably be some basic data binding. And finally, the MVVM pattern will take full advantage of advanced two-way data binding provided by the underlying framework. Let's not forget about the similarities, however. Remember that the problem with the forms and controls architecture is that UI design code and logic code are tightly coupled, making it difficult to write automated tests for our logic. This is mainly what MVC, MVP, and MVVM try to solve. They want to decouple the view and the model. But because of this, we need something in between. Depending on the technology and platform, this will be a controller, presenter, or view model. Decoupling components allows us to write different user interfaces or UI components for the same underlying model. And more importantly, it gives us the option of writing automated tests for the controllers, presenters, and view models. This helps us developers work faster and improve the stability and reliability of our code. So which UI architecture should you choose? A good piece of advice is to use the pattern that is used the most by other members of your community. In the web, this is often the MVC pattern. In older desktop technologies that have less powerful data binding features, MVP is popular. In modern desktop and mobile technologies, MVVM is probably your best choice. But whichever works best for you, be pragmatic. You might choose MVVM, but still need to add some code behind it because the data binding doesn't fulfill all your needs. That's okay, if you're still aiming for that separation of concerns and testability in other areas of your application.

Q: What is the controller in an MVC pattern responsible for?
A: receiving user input

Q: What is the overall shared goal of the MVC, MVP, and MVVM patterns?
A: decoupling the view and model

Q: Your team is planning to develop a web application. Which pattern is best suited for this, and why?
A: The MVC pattern is best because each one of the three components has clearly defined responsibilities.

Q: Why can advanced data binding, such as that associated with the MVVM pattern, be problematic?
A: Data binding can be difficult to debug.

### Combining patterns
- [Instructor] When designing our architecture, we'll usually have to combine different patterns to achieve our goals. In this course, we split up the architectural patterns in three categories: system patterns, application patterns, and user interface patterns. Generally speaking, we will probably be using at least one system pattern, one application pattern, and one UI pattern. For example, you could write a monolithic system that uses the microkernel pattern and has a model view presenter based user interface. Here's another example, you may have a system based on microservices, but each microservice could be built with a different application architecture. One could be layered, another could be using ports and adapters, and a third may be built with event sourcing. As a last example, consider a combination of the ports and adapters architecture with an event sourcing core. And as we saw, event sourcing can be combined with CQRS. This makes matters complex, but the important thing is to take a moment to think about your architecture and follow the guidelines that come with a chosen architecture so the structure remains clear for other developers. If you do that, the knowledge of the different architectures will help you write better software as you go forward.

Q: What should you do if the application you are currently working on or maintaining does not have a clearly defined architecture?
A: Give the application a clean and well-known architecture.

Q: Your development team is considering combining architecture patterns on their next project. Should the team do this, and why or why not?
A: It depends on the needs of the project because some combinations will not work well and others will.

--- 

## Key takeaways:

### What are software architecture patterns?
- **Definition**: Software architecture patterns are solutions to common problems in software design, defining components and their interactions.
- **Purpose**: They provide a structured way to solve recurring problems, making the software easier to understand and maintain.

These patterns help developers create more maintainable and recognizable code.

### Why software architecture patterns?
- **Advantages**: Software architecture patterns provide a solid plan for building complex applications, making them easier to maintain and extend.
- **Efficiency**: Using known patterns saves time and makes the code recognizable to other developers, improving team productivity.
- **Quality**: Patterns help improve the quality and structure of applications, reducing the risk of bugs and unmaintainable software.

These patterns are beneficial for both individual developers and teams.

### The difference with design patterns
- **Design Patterns**: These define a small number of components and their interactions within an application, focusing on specific pieces of code.
- **Software Architecture Patterns**: These occur at a higher level, addressing the structure of the entire application and the interactions between its components.
- **Scope**: Design patterns focus on individual pieces of code, while software architecture patterns provide a holistic view of the application's structure and component interactions.

These distinctions help you understand the different levels at which patterns can be applied in software development.

### Categories of patterns:

- **Three Categories**: Software architecture patterns are divided into System Patterns, Application Patterns, and User Interface Patterns.
- **System Patterns**: These help create a single application as viewed by the end-user, including patterns like monolith, microservices, and serverless.
- **Application Patterns**: These define the internal structure of a single executable, such as layered, onion, and hexagonal architectures.
- **UI Patterns**: These focus on the user interface, including patterns like Model-View-Controller (MVC), Model-View-Presenter (MVP), and Model-View-ViewModel (MVVM).

These categories help organize and understand the different types of software architecture patterns.

## System Patterns

### Monolith:

- **Definition**: A monolith is a single executable application containing all the logic to solve a problem.
- **Advantages**: It's simple to understand, implement, test, and deploy. Ideal for projects with a limited scope.
- **Disadvantages**: Can lead to tight coupling, making it hard to modify or extend. It may also result in a one-size-fits-all approach, limiting flexibility.

These points outline the main characteristics and considerations of using a monolithic architecture.

### N-tier:

- **Definition**: An N-tier architecture splits an application into multiple tiers, each responsible for a specific function, and can be physically separated.
- **Typical Setup**: A common example is the three-tier architecture, consisting of the presentation tier (UI), business tier (logic), and data tier (database).
- **Advantages**: Allows independent development, deployment, and scaling of tiers, although changes in one tier often require changes in others.

These points highlight the structure and benefits of using an N-tier architecture.

### Service-oriented:

- **Definition**: Service-oriented architecture (SOA) consists of multiple services representing business activities, often including standardized data contracts and an enterprise service bus (ESB).
- **Advantages**: SOA offers flexibility in development and deployment, scalability, and centralized business capabilities.
- **Disadvantages**: Requires strong central governance, which can reduce team autonomy and agility. It can also be costly and complex to set up and maintain.

These points provide an overview of the structure and considerations of using a service-oriented architecture.

### Microservices:

- **Definition**: Microservices architecture splits an application into multiple independent services, each responsible for specific business functionality.
- **Advantages**: Services are independent, scalable, and reduce bottlenecks, enhancing agility and reliability through automation.
- **Challenges**: Increased complexity, need for skilled engineers, and potential for complex communication patterns and data duplication.

These points outline the main characteristics, benefits, and challenges of using a microservices architecture.

### Serverless:

- **Types**: Serverless architectures can be Backend-as-a-Service (BaaS) or Function-as-a-Service (FaaS). The video focuses on FaaS, where functions run in short-lived, stateless containers managed by a cloud platform.
- **Advantages**: Serverless architectures scale easily, reduce infrastructure management, and allow for quick experimentation with new ideas.
- **Disadvantages**: Vendor lock-in, the need for stateless functions, potential cold start delays, and difficulty in cost estimation based on resource usage.

These points summarize the main aspects of serverless architectures discussed in the video.

### Distributed systems:

- **Transactional Integrity**: Ensuring data consistency across multiple services is challenging. Patterns like the saga pattern and transactional outbox pattern help maintain integrity.
- **Data Duplication**: Distributed systems often require data duplication to ensure services can operate independently, even if other services are unavailable.
- **Messaging**: Clear message structure (contracts) is crucial, and using message brokers can help manage asynchronous communication and ensure messages are eventually processed.

These points summarize the main challenges and solutions discussed in the video.

### Peer-to-peer:

- **Definition**: Peer-to-peer (P2P) architecture involves a network of applications communicating directly without a central server.
- **Advantages**: Cost-effective, easy to scale, and ideal for sharing resources like processing power, data, memory, or storage.
- **Drawbacks**: Potential security issues and limited applicability to specific scenarios, such as data sharing networks where viruses can spread more easily.

These points summarize the main aspects of peer-to-peer architecture discussed in the video.


## Application Patterns

### Layered:

- **Definition**: A layered application is structured into several layers, each with distinct responsibilities, where calls flow downwards from one layer to the next.
- **Structure**: Common layers include the presentation layer (UI), application layer, business layer, persistence layer, and database. Additional layers like caching can be added if needed.
- **Advantages and Drawbacks**: While it's a well-known and easy way to organize code, it can lead to highly coupled code that's hard to maintain and may require a lot of code to pass data between layers.

These points summarize the main aspects of the layered architecture discussed in the video.

### Onion:

- **Structure**: The onion architecture starts with the domain model at the core, surrounded by domain services, application services, and the infrastructure layer, resembling the layers of an onion.
- **Dependency Inversion Principle**: Unlike the layered architecture, the onion architecture inverts dependencies, placing interfaces in the inner layers and their implementations in the outer layers.
- **Advantages**: This architecture decouples business logic from infrastructure and UI concerns, making it easier to write automated tests and maintain the application.

These points summarize the main aspects of the onion architecture discussed in the video.

### Ports and adapters (or hexagonal):

- **Core Concept**: The core module contains the business logic or domain, which defines interfaces (ports) for interacting with the outside world. Adapters implement these ports.
- **Adapters**: There are primary adapters (e.g., user interfaces, console applications) that drive the application by making calls to the domain, and secondary adapters (e.g., storage clients, repositories) that are driven by the domain.
- **Advantages**: This architecture emphasizes loose coupling, easier testing, and reduced complexity by separating each adapter into its own module.

These points summarize the main aspects of the ports and adapters (hexagonal) architecture discussed in the video.

### Differences between layered, onion, and hexagonal:

- **Dependency Inversion**: The layered architecture has downward dependencies, while the onion and hexagonal architectures apply the dependency inversion principle, placing business logic at the center.
- **Module Structure**: In the onion architecture, infrastructure references the business layer, whereas in the hexagonal architecture, adapters are separated into their own modules.
- **Core Domain**: The onion architecture is more opinionated, defining application services, domain services, and a domain model, while the hexagonal architecture does not dictate the core domain structure.

These points highlight the main differences between these architectural patterns.

### Modular monolith:

- **Definition**: A modular monolith is a single running process that contains multiple subdomains and technical concerns but is divided into separate modules with their own architecture.
- **Advantages**: It offers loose coupling and increased agility similar to microservices, while being easier to run and deploy as a single application.
- **Challenges**: Requires discipline to maintain boundaries between modules and awareness of issues like data duplication and transactional integrity.

These points summarize the main aspects of the modular monolith architecture discussed in the video.

### Microkernel:

- **Core and Plugins**: The microkernel pattern consists of a core application with extensible plugins. The core defines contracts for plugins but doesn't need to know their details.
- **Flexibility**: This pattern allows for great flexibility, as features can be added later as extensions, and teams can work independently on the core and plugins.
- **Challenges**: Potential risks include the core API not being sufficient for future plugins and extensions possibly corrupting the entire application.

These points summarize the main aspects of the microkernel architecture discussed in the video.

### CQRS:

- **Separation of Models**: CQRS (Command Query Responsibility Segregation) separates the read and write models, with distinct models for reading and writing data.
- **Advantages**: Simplifies read queries, enhances scalability, and aligns with business language for better stakeholder communication.
- **Challenges**: Requires synchronization between read and write models, leading to potential data consistency issues and the concept of eventual consistency.

These points summarize the main aspects of the CQRS pattern discussed in the video.

### Event sourcing:

- **Event Storage**: Instead of storing the current state, event sourcing stores all events that have occurred to the data, allowing for rehydration or event replay to get the current state.
- **Advantages**: Provides a detailed trace of changes, facilitates easier communication with stakeholders, and allows for fixing bugs by replaying events.
- **Challenges**: Handling updates in external systems during event replay, managing changes to event code, and dealing with large amounts of events that can slow down the application.

These points summarize the main aspects of event sourcing discussed in the video.

### Combining CQRS and event sourcing:

- **Combination Benefits**: Combining CQRS and event sourcing leverages the advantages of both patterns, such as maintaining an audit trail and using user-friendly language, while improving scalability and read performance.
- **Implementation**: In an event-sourced application, the write model consists of events and handlers. Adding CQRS involves creating event handlers that populate a separate read model.
- **Challenges**: Combining these patterns increases complexity, requires managing potential inconsistencies between read and write models, and handling changes to event structures.

These points summarize the main aspects of combining CQRS and event sourcing discussed in the video.

## UI Patterns

### Forms and controls:

- **Components**: The pattern consists of two main components: the UI definition (markup language or general-purpose language) and the code behind that handles user interactions.
- **Use Case**: Ideal for desktop or mobile applications and proof-of-concept apps due to its simplicity and quick development.
- **Drawbacks**: As the system grows, the code behind can become complex and difficult to test, leading to potential bugs and maintenance challenges.

These points summarize the main aspects of the Forms and Controls pattern discussed in the video.

### Model-View-Controller:

- **Components**: MVC consists of three components: the model (manages data), the view (presents data), and the controller (handles user input and updates the model).
- **Advantages**: Provides a clean separation of concerns, enabling parallel development and easier unit testing. It's widely used in web frameworks but also applicable to desktop and mobile applications.
- **Challenges**: Risk of bloated controllers if they handle too much logic, input validation, and data access. Combining MVC with other patterns can help manage complexity.

These points summarize the main aspects of the MVC pattern discussed in the video.

### Model-View-Presenter:

- **Components**: MVP consists of three components: the Model (manages data), the View (handles UI), and the Presenter (manages UI logic and updates the Model).
- **Variations**: There are two variations of MVP: Passive View (UI logic in Presenter) and Supervising Controller (UI contains rendering details, Presenter handles complex logic).
- **Advantages**: Provides a clean separation of concerns, making parts of the application easier to test and maintain, especially suitable for desktop or mobile applications.

These points summarize the main aspects of the MVP pattern discussed in the video.

### Model-View-ViewModel:

- **Components**: MVVM consists of three components: the Model (business logic and data), the View (UI), and the ViewModel (intermediary that handles data binding between the Model and View).
- **Data Binding**: Advanced data binding techniques connect the View to the ViewModel, allowing for two-way communication without direct links at compile time.
- **Advantages and Drawbacks**: MVVM provides a clean separation of concerns and is great for desktop and mobile applications with data binding support. However, it can be overkill for simple applications and harder to debug due to the complexity of data binding.

These points summarize the main aspects of the MVVM pattern discussed in the video.

### Differences between MVC, MVP, and MVVM:

- **User Interaction Handling**: In MVC, the controller handles user interactions, while in MVP and MVVM, the view handles user interactions.
- **View Awareness**: In MVC, the view binds directly to the model. In MVP, the view's awareness of the model depends on the flavor (supervising controller or passive view). In MVVM, the view usually binds to the view model, not the model.
- **Data Binding**: MVC and MVP (supervising controller) may use basic data binding, while MVVM leverages advanced two-way data binding provided by the framework.

These points summarize the main differences between MVC, MVP, and MVVM discussed in the video.

--- 